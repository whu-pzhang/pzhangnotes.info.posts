---
title: cs231nä½œä¸š3ç¬”è®°
author: pzhang
date: 2018-12-20
lastMod: 2018-12-20
markup: mmark
mathjax: true
categories:
  - è®¡ç®—æœºè§†è§‰
tags:
  - Python
  - NumPy
  - PyTorch

draft: true
slug: cs231n-assignment3
---

## ç®€ä»‹

åœ¨ä½œä¸š 2 ä¸­æ‰‹æ’¸ CNN åï¼Œcs231n è®²è¿°äº† RNNï¼ŒLSTMï¼ŒGRU ä»¥åŠè¯­è¨€æ¨¡å‹ã€å›¾åƒæ ‡æ³¨ã€æ£€æµ‹ã€å®šä½ã€åˆ†å‰²ã€è¯†åˆ«ç­‰å¤šæ–¹é¢çš„å†…å®¹ã€‚

## RNN captioning

å¸¸è§„ DNN å’Œ CNN åªèƒ½ä¾æ¬¡å¤„ç†ä¸€ä¸ªä¸ªçš„è¾“å…¥ï¼Œè¾“å…¥ä¹‹é—´æ˜¯å®Œå…¨æ²¡æœ‰è”ç³»çš„ï¼Œè¿™å¯¹äºå›¾åƒåˆ†ç±»çš„ä»»åŠ¡æ¥è¯´
æ˜¯æ²¡æœ‰é—®é¢˜çš„ï¼Œä½†æŸäº›éœ€è¦å¤„ç†åºåˆ—ä¹‹é—´å…³ç³»çš„ä»»åŠ¡è€Œè¨€å°±ä¸é€‚åˆäº†ã€‚ä¾‹å¦‚ï¼š

1.  å›¾åƒæ ‡æ³¨é—®é¢˜(one to many)ï¼š image -> sequence of words
2.  æƒ…æ„Ÿåˆ†ç±»(many to one): sequence of words -> sentiment
3.  æœºå™¨ç¿»è¯‘(many to many): seq of words -> seq of words
4.  å¸§çº§åˆ«çš„è§†é¢‘åˆ†ç±»(many to many)
5.  â€¦â€¦

ä¸ºäº†æ›´å¥½åœ°å¤„ç†åºåˆ—çš„ä¿¡æ¯ï¼ŒRNN(Recurrent Neural Network)è¯ç”Ÿäº†ã€‚
RNN éœ€è¦é¢„æµ‹ä¸€ä¸ªå’Œæ—¶é—´ç›¸å…³çš„é‡ï¼Œå…¶åŸºæœ¬æ¶æ„å¦‚ä¸‹ï¼š

![](/images/rnn.jpg)

æ¯ä¸ªæ—¶é—´æ­¥éƒ½è¦æ ¹æ®å‰ä¸€ä¸ªçŠ¶æ€å’Œå½“å‰è¾“å…¥è®¡ç®—ä¸€ä¸ªæ–°çš„çŠ¶æ€ã€‚

$$
\boldsymbol{h}_t = f_W (\boldsymbol{h}_{t-1}, \boldsymbol{x}_t) \\
\downarrow \\
\boldsymbol{h}_t = tanh (\mathbf{W}_{hh}\boldsymbol{h}_{t-1} + \mathbf{W}_{xh} \boldsymbol{x}_t)
$$

å‘ä¸Šçš„ç®­å¤´ä¸ºæ¯ä¸ªæ—¶é—´æ­¥çš„è¾“å‡ºï¼Œæ˜¯ä¸€ä¸ª softmax å±‚

$$
\boldsymbol{y}_t = Softmax (\mathbf{W}_{hy} * \boldsymbol{h}_t)
$$

æ ¹æ®ä¸Šè¿°å…¬å¼ï¼ŒRNN å•å…ƒçš„ `rnn_step_forward` å¦‚ä¸‹ï¼š

```python
prev_hWh = prev_h @ Wh                          # (1)
xWx = x @ Wx                                    # (2)
hsum = prev_hWh + xWx + b                       # (3)
next_h = np.tanh(hsum)                          # (4)
```

æ ¹æ®è®¡ç®—å›¾åæ¨ï¼Œbackward ä¹Ÿå¾ˆç®€å•ï¼š

```python
dhsum = (1 - np.tanh(hsum)**2) * dnext_h      # (4)
dprev_hWh = dhsum                             # (3)
dxWx = dhsum                                  # (3)
db = np.sum(dhsum, axis=0)                    # (3)
dx = dxWx @ Wx.T                              # (2)
dWx = x.T @ dxWx                              # (2)
dWh = prev_h.T @ dprev_hWh                    # (1)
dprev_h = dprev_hWh @ Wh.T                    # (1)
```

æ¥ä¸‹æ¥å°±æ˜¯å®Œæ•´çš„ RNN äº†ï¼Œforward è¿‡ç¨‹éœ€è¦å¯¹ RNN å•å…ƒå¾ªç¯ `T` æ¬¡ï¼ˆ`T`ä¸ºåºåˆ—é•¿åº¦ï¼‰ï¼Œåœ¨å¾ªç¯å†…éƒ¨æ¯æ¬¡è®°å¾—æ›´æ–° $\boldsymbol{h}_t$ å³å¯ã€‚

backward è¿‡ç¨‹å’Œä»¥å‰çš„ç¥ç»ç½‘ç»œä¸å¤ªä¸€æ ·ï¼ŒRNN ä»ä¸Šæ¸¸ä¼ è¿‡æ¥çš„æ¢¯åº¦ä¸åªä¸€ä¸ªï¼Œé™¤äº†ä»å³è¾¹ä¼ è¿‡æ¥çš„æ¢¯åº¦å¤–ï¼Œ
è¿˜æœ‰æ¯ä¸ªæ—¶é—´ç‚¹ï¼ˆä¸Šé¢ï¼‰ä¼ è¿‡æ¥çš„æ¢¯åº¦ã€‚é¦–å…ˆéœ€è¦é€†åºå¾ªç¯ï¼Œç„¶åæ¯ä¸ªå¾ªç¯å†…æ›´æ–° RNN å•å…ƒéœ€è¦çš„æ¢¯åº¦å€¼ã€‚
æ­¤å¤–ï¼Œåœ¨ RNN ä¸­ï¼ŒWx, Wh, b è¿™ä¸‰ä¸ªå‚æ•°æ˜¯å…±äº«çš„ï¼Œå¯¹æ¯ä¸ªæ—¶é—´æ­¥éƒ½æ˜¯ä¸€æ ·çš„ï¼Œå› æ­¤å®ƒä»¬çš„æ¢¯åº¦æ˜¯ä¸€ä¸ªç´¯åŠ çš„å€¼ã€‚

```python
dprev_ht = np.zeros((N, H))
for t in reversed(range(T)):
    dx[:, t, :], dprev_ht, dWxt, dWht, dbt = rnn_step_backward(
        dh[:, t, :] + dprev_ht, cache[t])
    dWx += dWxt
    dWh += dWht
    db += dbt
dh0 = dprev_ht
```

åœ¨ç”¨ RNN å¯¹å›¾åƒè¿›è¡Œæ ‡æ³¨å‰ï¼Œè¿˜éœ€è¦è¿›è¡Œè¯åµŒå…¥(word embeding)æ“ä½œã€‚
ç¥ç»ç½‘ç»œä¸èƒ½å°†å•è¯ä½œä¸ºè¾“å…¥ï¼Œæ‰€ä»¥éœ€è¦å°†å•è¯æ˜ å°„ä¸ºå•è¯ç´¢å¼•çš„å½¢å¼ã€‚

ç°åœ¨å°±å¯ä»¥æ¥æ­å»º RNN çš„æ¶æ„äº†ã€‚é¦–å…ˆéœ€è¦æŠŠå›¾åƒç» CNN æå–çš„ç‰¹å¾ï¼ˆä½œä¸šä¸­é‡‡ç”¨çš„æ˜¯åœ¨ ImageNet æ•°æ®é›†ä¸Šé¢„è®­ç»ƒçš„ VGG16 æ¨¡å‹çš„ fc7 å±‚æå–å¾—åˆ°çš„ç‰¹å¾ï¼‰é€šè¿‡å…¨è¿æ¥å±‚è½¬æ¢ä¸ºåˆå§‹çš„éšè—çŠ¶æ€ï¼ˆ$\boldsymbol{h}_0$ï¼‰ï¼Œæ¥ç€å°† captions åšè¯åµŒå…¥è¾“å…¥ RNN å•å…ƒä¸­ï¼Œå†åˆ©ç”¨ä¸€ä¸ªä»¿å°„å˜æ¢å°† RNN å•å…ƒçš„è¾“å‡ºè½¬æ¢ä¸ºå•è¯å­—å…¸ç´¢å¼•ï¼Œæ¥ç€é‡‡ç”¨ softmax æŸå¤±è®¡ç®— lossã€‚

```python
h0, h0cache = affine_forward(features, W_proj, b_proj)
weout, wecache = word_embedding_forward(captions_in, W_embed)

if self.cell_type == 'rnn':
    rnnout, rnncache = rnn_forward(weout, h0, Wx, Wh, b)

x, xcache = temporal_affine_forward(rnnout, W_vocab, b_vocab)
loss, dx = temporal_softmax_loss(x, captions_out, mask)
```

ä¸Šé¢æè¿°çš„æ˜¯ RNN è®­ç»ƒè¿‡ç¨‹ï¼Œæµ‹è¯•æ—¶æ²¡æœ‰çœŸå€¼æ ‡æ³¨ä½œä¸ºè¾“å…¥ï¼Œéœ€è¦ä¸€ä¸ªèµ·å§‹å•è¯ï¼ˆ`<START>`ï¼‰ä½œä¸ºå¼€å§‹ï¼Œç„¶åæŒ‰åºåˆ—ä¾æ¬¡æ›´æ–°éšè—çŠ¶æ€ï¼Œå¹¶é¢„æµ‹è¾“å‡ºä¸‹ä¸€ä¸ªæ ‡æ³¨å•è¯ã€‚

```python
prev_h, _ = affine_forward(features, W_proj, b_proj)
captions[:, 0] = self._start
x = self._start * np.ones((N, ), dtype=np.int32)
for t in range(1, max_length):
    embed, _ = word_embedding_forward(x, W_embed)

    if self.cell_type == 'rnn':
        next_h, _ = rnn_step_forward(embed, prev_h, Wx, Wh, b)

    prev_h = next_h
    out, _ = affine_forward(next_h, W_vocab, b_vocab)
    idx = np.argmax(out, axis=1)
    captions[:, t] = idx
```

## LSTM captioning

RNN åº”è¯¥èƒ½å¤Ÿè®°ä½è®¸å¤šæ—¶é—´æ­¥ä¹‹å‰è§è¿‡çš„ä¿¡æ¯ï¼Œä½†å®é™…ä¸­ç”±äºæ¢¯åº¦æ¶ˆå¤±ï¼ˆvanishing gradient problemï¼‰é—®é¢˜ï¼Œ
éšç€å±‚æ•°çš„å¢åŠ ï¼Œç½‘ç»œå°†å˜å¾—æ— æ³•è®­ç»ƒã€‚LSTM(Long Short Term Memory)å’Œ GRU éƒ½æ˜¯ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜è€Œæå‡ºçš„ã€‚

LSTM å•å…ƒç»“æ„å¦‚ä¸‹ï¼š

![](./images/lstm.png)

forward è¿‡ç¨‹è®¡ç®—å…¬å¼å¦‚ä¸‹ï¼š

$$
\begin{align}
\begin{pmatrix}
i \\
f \\
o \\
g
\end{pmatrix} & =
\begin{pmatrix}
\sigma \\
\sigma \\
\sigma \\
\tanh
\end{pmatrix} \,
\mathbf{W}
\begin{pmatrix}
h*{t-1} \\
x_t
\end{pmatrix} \\
\\
c_t & = f \odot c*{t-1} + i \odot g \\
h_t & = o \odot \tanh(c_t)
\end{align}
$$

æ³¨æ„åˆ°æ¯ä¸ª LSTM å•å…ƒæœ‰ 3 ä¸ªè¾“å…¥ï¼š$c, h, x$ã€‚å®é™…è®¡ç®—æ—¶ 4 ä¸ª gate çš„çº¿æ€§éƒ¨åˆ†å¯ä»¥é€šè¿‡ä¸€æ¬¡è®¡ç®—å®Œæˆï¼Œç„¶åå°†ä¸åŒ gate å¯¹åº”çš„å€¼åˆ†å¼€å³å¯ã€‚

```python
H = prev_h.shape[1]
z = x @ Wx + prev_h @ Wh + b
igate = sigmoid(z[:, :H])
fgate = sigmoid(z[:, H:2 * H])
ogate = sigmoid(z[:, 2 * H:3 * H])
ggate = np.tanh(z[:, 3 * H:])

next_c = fgate * prev_c + igate * ggate
next_h = ogate * np.tanh(next_c)
```

backward æ—¶ï¼Œç›¸æ¯” RNNï¼Œåä¼ è¿‡æ¥çš„å€¼æœ‰ä¸¤ä¸ª **`dnext_h`, `dnext_c`**ã€‚æ±‚ï¼š
`dx`, `dWx`, `dWh`, `db`, `dprev_h` å’Œ `dprev_c` çš„æ¢¯åº¦ã€‚å¼„æ¸…æ¥šå“ªäº›å˜é‡ä¹‹é—´æœ‰å…³è”ï¼Œç„¶ååˆ©ç”¨é“¾å¼æ³•åˆ™å³å¯ï¼š

```python
dogate = dnext_h * np.tanh(next_c)
dnext_c += dnext_h * ogate * (1.0 - np.tanh(next_c)**2)
dfgate = dnext_c * prev_c
dprev_c = dnext_c * fgate
digate = dnext_c * ggate
dggate = dnext_c * igate

dz = np.zeros((N, 4 * H))
dz[:, :H] = digate * igate * (1.0 - igate)
dz[:, H:2 * H] = dfgate * fgate * (1. - fgate)
dz[:, 2 * H:3 * H] = dogate * ogate * (1.0 - ogate)
dz[:, 3 * H:4 * H] = dggate * (1.0 - ggate**2)

dx = dz @ Wx.T
dWx = x.T @ dz
dprev_h = dz @ Wh.T
dWh = prev_h.T @ dz
db = np.sum(dz, axis=0)
```

å®Œæ•´çš„ LSTM å¤§ä½“å’Œ RNN ç›¸åŒï¼Œæ³¨æ„å¤šäº†ä¸€ä¸ªå˜é‡ `c`ï¼Œä¸è®ºæ˜¯ forward å’Œ backward éƒ½è®°å¾—åœ¨å¾ªç¯é‡Œæ›´æ–°å³å¯ã€‚

## Network Visualization

ä¹‹å‰è®­ç»ƒæ¨¡å‹éƒ½æ˜¯åˆ©ç”¨ SGD æ¥æ›´æ–°æ¨¡å‹å‚æ•°ä½¿å…¶è¾¾åˆ°æŸå¤±å‡½æ•°å®šä¹‰ä¸‹çš„è¦æ±‚ã€‚è€Œåœ¨è¿™ä¸€èŠ‚ä¸­ï¼Œæˆ‘ä»¬åˆ©ç”¨å·²ç»è®­ç»ƒå¥½çš„é¢„è®­ç»ƒæ¨¡å‹æ¥å®šä¹‰ç›¸å¯¹äºå›¾åƒçš„æŸå¤±å‡½æ•°ï¼Œåˆ©ç”¨åå‘ä¼ æ’­è®¡ç®—å›¾åƒåƒç´ çš„æ¢¯åº¦ï¼Œä¿æŒæ¨¡å‹ä¸å˜ï¼Œé€šè¿‡æ›´æ–°å›¾åƒæ¥æœ€å°åŒ–æŸå¤±å‡½æ•°ã€‚

ä¸»è¦åŒ…æ‹¬ä¸‰ä¸ªæ–¹é¢çš„å†…å®¹ï¼š

* æ˜¾è‘—æ€§å›¾ï¼ˆSaliency Mapsï¼‰

æ˜¾è‘—æ€§å›¾å‘Šè¯‰æˆ‘ä»¬å›¾åƒä¸­æ¯ä¸ªåƒç´ å½±å“å›¾åƒç±»åˆ«åˆ†æ•°çš„ç¨‹åº¦ã€‚é€šè¿‡è®¡ç®—æ­£ç¡®ç±»æœªè§„èŒƒåŒ–çš„åˆ†æ•°ç›¸å¯¹äºæ¯ä¸ªåƒç´ çš„æ¢¯åº¦æ¥å¾—åˆ°ã€‚

```python
scores = model(X) # correct class scores
scores = scores.gather(1, y.view(-1, 1)).squeeze() # backward
scores.backward(torch.ones(X.size(0)))

 # image gradient
saliency = X.grad

 # absolute the value and take the maximum value over the 3 channels
saliency = torch.abs(saliency)
saliency, _ = torch.max(saliency, dim=1)
```

* Fooling images

Fooling images åˆ™æ˜¯åœ¨ç»™å®šå›¾åƒå’Œç±»åˆ«æ—¶ï¼Œé€šè¿‡æ¢¯åº¦ä¸Šå‡æ³•ä¸æ–­åœ°æ›´æ–°å›¾åƒï¼Œæœ€åä½¿å¾—æ¨¡å‹è®¤ä¸ºè¯¥å›¾åƒå°±æ˜¯è¿™ä¸ªç±»åˆ«çš„å›¾åƒä¸ºæ­¢ã€‚

```python
while (True):
    scores = model(X*fooling)
    idx = torch.argmax(scores)

    if idx.item() == target_y:
        break

    scores[0, target_y].backward()

    dX = X_fooling.grad.data

    # update image using gradient ascent
    X_fooling.data += learning_rate * (dX / dX.norm())

    X_fooling.grad.zero_()
```

* ç±»åˆ«å¯è§†åŒ–ï¼ˆClass Visualizationï¼‰

è¿™é‡Œå’Œ fooling images å·®ä¸å¤šï¼Œéƒ½æ˜¯é¢„è®­ç»ƒçš„æ¨¡å‹é€šè¿‡æ¢¯åº¦ä¸Šå‡å°†è¾“å…¥çš„éšæœºå™ªéŸ³å›¾åƒå˜ä¸ºæŒ‡å®šç±»åˆ«çš„å›¾åƒã€‚

```python
scores = model(img)
loss = scores[0, target_y] - l2_reg * img.norm()
loss.backward()
grad = img.grad.data
img.data += learning_rate * grad
img.grad.zero_()
```

## Style Transfer

é£æ ¼è¿ç§»çš„ç›®çš„æ˜¯å°†å‚è€ƒå›¾åƒçš„é£æ ¼åº”ç”¨äºç›®æ ‡å›¾åƒï¼ŒåŒæ—¶ä¿ç•™ç›®æ ‡å›¾åƒçš„å†…å®¹ï¼Œä»è€Œç”Ÿæˆä¸€å‰¯æ–°çš„å›¾åƒã€‚

![](./images/20190329.jpg)

é£æ ¼è¿ç§»çš„æ€æƒ³ä¸çº¹ç†ç”Ÿæˆçš„æƒ³æ³•å¯†åˆ‡ç›¸å…³ã€‚å®ç°é£æ ¼è¿ç§»èƒŒåçš„å…³é”®æ€æƒ³ä¸æ‰€æœ‰æ·±åº¦å­¦ä¹ ç®—æ³•çš„æ€æƒ³ä¸€æ ·ï¼š
éœ€è¦å…ˆå®šä¹‰ä¸€ä¸ªæŸå¤±å‡½æ•°å®šä¹‰è¦å®ç°çš„ç›®æ ‡ï¼Œç„¶åé‡‡ç”¨æ¢¯åº¦ä¸‹é™æ³•æœ€å°åŒ–è¿™ä¸ªæŸå¤±å‡½æ•°ã€‚
ç›®æ ‡å°±æ˜¯ä¿å­˜åŸå§‹å›¾åƒå†…å®¹çš„åŒæ—¶å®ç°é£æ ¼åŒ–ï¼Œè‹¥èƒ½åœ¨æ•°å­¦ä¸Šç»™å‡º content å’Œ style çš„å®šä¹‰ï¼Œé‚£ä¹ˆæŸå¤±å‡½æ•°
å¯ä»¥å®šä¹‰å¦‚ä¸‹ï¼š

```
loss = distance(style(reference_image) - style(generated_image)) +
       distance(content(original_image) - content(generated_image))
```

è¿™é‡Œçš„ `distance` æ˜¯ä¸€ä¸ªèŒƒæ•°ï¼Œå¦‚ L2 èŒƒæ•°ã€‚`content` å’Œ `style` åˆ†åˆ«æ˜¯è®¡ç®—è¾“å…¥å›¾åƒå†…å®¹å’Œé£æ ¼
çš„å‡½æ•°ã€‚

### content loss

å†…å®¹æŸå¤±æè¿°çš„æ˜¯ç½‘ç»œä»ç›®æ ‡å›¾åƒæå–å‡ºçš„ç‰¹å¾å›¾ä¸ä»ç”Ÿæˆå›¾åƒæå–çš„ç‰¹å¾å›¾ä¹‹é—´çš„å·®åˆ«ã€‚é€šå¸¸é€‰æ‹©çš„æ˜¯é è¿‘
é¡¶éƒ¨çš„æŸä¸€ç‰¹å¾å›¾æ¥è¿›è¡Œé€å…ƒç´ æ¯”è¾ƒã€‚ä»£ç å¦‚ä¸‹ï¼š

```python
def content_loss(content_weight, content_current, content_original):
    """
    Compute the content loss for style transfer.
    
    Inputs:
    - content_weight: Scalar giving the weighting for the content loss.
    - content_current: features of the current image; this is a PyTorch Tensor of shape
      (1, C_l, H_l, W_l).
    - content_target: features of the content image, Tensor with shape (1, C_l, H_l, W_l).
    
    Returns:
    - scalar content loss
    """
    loss = content_weight * torch.sum((content_current - content_original)**2)
    return loss
```


### style loss

ä¸åŒäºå†…å®¹æŸå¤±ï¼Œé£æ ¼æŸå¤±ä½¿ç”¨å·ç§¯ç½‘ç»œçš„å¤šä¸ªå±‚æ¥å®šä¹‰ï¼Œä»¥æ­¤æ¥æ•æ‰å‚è€ƒå›¾åƒå’Œç”Ÿæˆå›¾åƒä¸Šä¸åŒç©ºé—´å°ºåº¦ä¸Š
çš„ä¿¡æ¯ã€‚ä½¿ç”¨ Gram Matrix æ¥è¡¨ç¤ºä¸åŒæ¿€æ´»å±‚ä¹‹é—´çš„ç›¸å…³æ€§ï¼šæˆ‘ä»¬å¸Œæœ›ç”Ÿæˆå›¾åƒçš„æ¿€æ´»ç»Ÿè®¡é‡ä¸é£æ ¼å›¾åƒçš„
æ¿€æ´»ç»Ÿè®¡é‡ç›¸åŒ¹é…ã€‚æœ‰å¾ˆå¤šç§æ–¹æ³•å¯ä»¥æ¥è¡¨ç¤ºè¿™ç§ç›¸å…³ï¼Œä½† Gram Matrix æ˜“äºè®¡ç®—ä¸”æ•ˆæœå¾ˆå¥½ã€‚

å¯¹äº shape ä¸º $(C_l, M_l)$ çš„ç‰¹å¾å›¾ $F^l$ ï¼Œå…¶ Gram çŸ©é˜µ shape ä¸º $(C_l, C_l)$:

$$
G_{ij}^l = \sum_k {F_{ik}^l F_{jk}^l}
$$

å‡å®š $G^l$ ä¸ºå½“å‰å›¾åƒçš„ Gram çŸ©é˜µï¼Œ$A^l$ ä¸ºå‚è€ƒé£æ ¼å›¾åƒçš„ç‰¹å¾å›¾ Gram çŸ©é˜µï¼Œ$w_l$ ä¸ºæƒé‡ï¼Œ
é‚£ä¹ˆ $l$ å±‚çš„é£æ ¼æŸå¤±å¯ä»¥ç®€å•çš„å®šä¹‰ä¸ºä¸¤ä¸ª Gram çŸ©é˜µä¹‹é—´çš„æ¬§æ°è·ç¦»ï¼š

$$
L_s^l = w_l \sum_{i,j} {(G_{ij}^l - A_{ij}^l)^2}
$$

è€Œé£æ ¼æŸå¤±æ˜¯å¤šä¸ªå±‚çš„æŸå¤±å’Œï¼š

$$
L_s = \sum_{l \in \mathcal{L}} {L_s^l}
$$

é¦–å…ˆå®ç° Gram çŸ©é˜µçš„è®¡ç®—ï¼š

```python
def gram_matrix(features, normalize=True):
    """
    Compute the Gram matrix from features.
    
    Inputs:
    - features: PyTorch Tensor of shape (N, C, H, W) giving features for
      a batch of N images.
    - normalize: optional, whether to normalize the Gram matrix
        If True, divide the Gram matrix by the number of neurons (H * W * C)
    
    Returns:
    - gram: PyTorch Tensor of shape (N, C, C) giving the
      (optionally normalized) Gram matrices for the N input images.
    """
    N, C, H, W = features.size()
    features_reshaped = features.reshape(N, C, H * W)
    gram = torch.bmm(features_reshaped, features_reshaped.transpose(1, 2))
    if normalize:
        gram /= H * W * C
    return gram
```

æ¥ç€ï¼Œæˆ‘ä»¬å®ç°é£æ ¼æŸå¤±å‡½æ•°ï¼š

```python
def style_loss(feats, style_layers, style_targets, style_weights):
    """
    Computes the style loss at a set of layers.
    
    Inputs:
    - feats: list of the features at every layer of the current image, as produced by
      the extract_features function.
    - style_layers: List of layer indices into feats giving the layers to include in the
      style loss.
    - style_targets: List of the same length as style_layers, where style_targets[i] is
      a PyTorch Tensor giving the Gram matrix of the source style image computed at
      layer style_layers[i].
    - style_weights: List of the same length as style_layers, where style_weights[i]
      is a scalar giving the weight for the style loss at layer style_layers[i].
      
    Returns:
    - style_loss: A PyTorch Tensor holding a scalar giving the style loss.
    """
    # Hint: you can do this with one for loop over the style layers, and should
    # not be very much code (~5 lines). You will need to use your gram_matrix function.
    loss = torch.FloatTensor([0]).type(dtype)
    for i, idx in enumerate(style_layers):
        gram = gram_matrix(feats[idx])
        loss += torch.sum(style_weights[i] * (gram - style_targets[i])**2)       
    return loss
```

### Total-variation regularization

é™¤äº†å†…å®¹æŸå¤±å’Œé£æ ¼æŸå¤±ä¹‹å¤–ï¼Œè¿˜éœ€è¦æ·»åŠ ä¸€ä¸ªå…¨å˜åˆ†æ­£åˆ™åŒ–æŸå¤±ï¼Œä½¿ç”Ÿæˆå›¾åƒ
çš„åƒç´ å…·æœ‰ç©ºé—´è¿ç»­æ€§å’Œå¹³æ»‘ï¼Œé¿å…å›¾åƒè¿‡åº¦åƒç´ åŒ–ã€‚

å…¨å˜åˆ†æŸå¤±å®šä¹‰ä¸ºæ°´å¹³å’Œå‚ç›´æ–¹å‘ç›¸é‚»åƒç´ å·®çš„å¹³æ–¹å’Œï¼Œå¯¹äºä¸åŒçš„é€šé“ä¹‹é—´ä¹Ÿæ˜¯ç›¸åŠ ã€‚

```python
def tv_loss(img, tv_weight):
    """
    Compute total variation loss.
    
    Inputs:
    - img: PyTorch Variable of shape (1, 3, H, W) holding an input image.
    - tv_weight: Scalar giving the weight w_t to use for the TV loss.
    
    Returns:
    - loss: PyTorch Variable holding a scalar giving the total variation loss
      for img weighted by tv_weight.
    """
    # Your implementation should be vectorized and not require any loops!
    hsum = torch.sum((img[:,:,:-1,:] - img[:,:,1:,:])**2)
    wsum = torch.sum((img[:,:,:,:-1] - img[:,:,:,1:])**2)
    return tv_weight * (hsum + wsum)
```

åœ¨é£æ ¼è¿ç§»ä¸­ï¼Œæˆ‘ä»¬éœ€è¦æœ€å°åŒ–çš„æŸå¤±ä¸ºå†…å®¹æŸå¤±ã€é£æ ¼æŸå¤±å’Œå…¨å˜å·®æŸå¤±è¿™ä¸‰éƒ¨åˆ†ä¹‹å’Œã€‚
æ¥ä¸‹æ¥ï¼Œåªéœ€è¦å°†è¿™ä¸‰éƒ¨åˆ†ç»„åˆèµ·æ¥ï¼Œåˆ©ç”¨æ¢¯åº¦ä¸‹é™æ³•æ¥å¾—åˆ°æœ€åçš„å›¾åƒå³å¯ã€‚å…·ä½“å¯ä»¥å‚è€ƒ
[StyleTransfer-Pytorch.ipynb](https://github.com/whu-pzhang/cs231n/blob/master/assignment3/StyleTransfer-PyTorch.ipynb)


## GAN

åœ¨æ­¤ä¹‹å‰ï¼Œcs231nä¸­æ‰€æœ‰çš„ç¥ç»ç½‘ç»œéƒ½æ˜¯åˆ¤åˆ«å¼æ¨¡å‹ï¼Œä»ç»™å®šçš„è¾“å…¥å¾—åˆ°ä¸€ä¸ªç±»åˆ«æ ‡è®°è¾“å‡ºã€‚å…¶åº”ç”¨èŒƒå›´ä»å›¾åƒåˆ†ç±»
åˆ°ç”Ÿæˆå›¾åƒæè¿°ã€‚åœ¨è¿™ä¸€å°èŠ‚ä¸­ï¼Œæˆ‘ä»¬åˆ©ç”¨ç¥ç»ç½‘ç»œæ¥æ„å»ºç”Ÿæˆæ¨¡å‹ã€‚

2014å¹´ï¼Œ[Goodfellow et al.](https://arxiv.org/abs/1406.2661)æå‡ºäº†è®­ç»ƒç”Ÿæˆæ¨¡å‹çš„ç”Ÿæˆå¯¹æŠ—ç½‘ç»œ
ï¼ˆGenerative Adversarial Networksï¼ŒGANï¼‰ã€‚åœ¨è¯¥æ–¹æ³•ä¸­ï¼Œéœ€è¦æ„å»ºä¸¤ä¸ªä¸åŒçš„ç½‘ç»œï¼š
ç¬¬ä¸€ä¸ªç½‘ç»œæ˜¯ä¼ ç»Ÿçš„åˆ†ç±»ç½‘ç»œï¼Œç§°ä¸ºåˆ¤åˆ«å™¨ï¼ˆdiscriminatorï¼‰ï¼Œå…¶åŠŸèƒ½æ˜¯åˆ¤æ–­è¾“å…¥å›¾åƒæ˜¯çœŸå®çš„ï¼ˆè¾“å…¥è®­ç»ƒé›†ï¼‰
è¿˜æ˜¯å‡çš„ï¼ˆä¸å±äºè®­ç»ƒé›†ï¼‰ã€‚ç¬¬äºŒä¸ªç½‘ç»œç§°ä¸ºç”Ÿæˆå™¨ï¼ˆgeneratorï¼‰ï¼Œå°†éšæœºå™ªå£°ä½œä¸ºè¾“å…¥å¹¶äº§ç”Ÿä¸€å¼ å›¾åƒã€‚
ç”Ÿæˆå™¨çš„ç›®æ ‡æ˜¯éª—è¿‡åˆ¤åˆ«å™¨ï¼Œä½¿å…¶è®¤ä¸ºå…¶ç”Ÿæˆçš„å›¾åƒæ˜¯çœŸå®çš„ã€‚

å¯ä»¥æŠŠåˆ¤åˆ«å™¨å’Œç”Ÿæˆå™¨çš„åšå¼ˆçœ‹ä½œæ˜¯ä¸€ä¸ªæœ€å°æœ€å¤§çš„è¿‡ç¨‹ï¼š

$$
\min_{G} \max_{D} \mathbb{E}_{x~p_{data}} \left[ \log D(x) \right] + \mathbb{E}_{z~p(z)} \left[ \log (1-D(G(z))) \right]
$$

å…¶ä¸­ï¼Œ$z~p(z)$ ä¸ºéšæœºå™ªå£°æ ·æœ¬ï¼Œ$G(z)$ ä¸ºç”Ÿæˆå™¨ $G$ äº§ç”Ÿçš„å›¾åƒï¼Œ$D$ ä¸ºåˆ¤åˆ«å™¨çš„è¾“å‡ºï¼Œè¡¨ç¤ºè¾“å…¥ä¸º
çœŸå®å›¾åƒçš„æ¦‚ç‡ã€‚åœ¨[Goodfellow et al.](https://arxiv.org/abs/1406.2661)ä¸­ï¼Œä½œè€…åˆ†æäº†è¿™ä¸ª
æœ€å°æœ€å¤§è¿‡ç¨‹å’Œæœ€å°åŒ–è®­ç»ƒæ•°æ®åˆ†å¸ƒä¸ç”Ÿæˆæ ·æœ¬ä¹‹é—´Jensen-Shannonæ•£åº¦çš„å…³è”ã€‚

ä¸ºäº†ä¼˜åŒ–è¿™ä¸ªæœ€å°æœ€å¤§è¿‡ç¨‹ï¼Œå¯ä»¥é€‰æ‹©å¯¹ $G$ è¿›è¡Œæ¢¯åº¦ä¸‹é™ä¼˜åŒ–ï¼Œå¯¹ $D$ è¿›è¡Œæ¢¯åº¦ä¸Šå‡ä¼˜åŒ–ï¼š

1. æ›´æ–°ç”Ÿæˆå™¨ $G$ ä½¿å¾—åˆ¤åˆ«å™¨ä½œå‡ºæ­£ç¡®åˆ¤æ–­çš„æ¦‚ç‡æœ€å°
2. æ›´æ–°åˆ¤åˆ«å™¨ $D$ ä½¿å¾—åˆ¤åˆ«å™¨ä½œå‡ºæ­£ç¡®åˆ¤æ–­çš„æ¦‚ç‡æœ€å¤§

ä½†æ˜¯ä¸Šè¿°ä¸¤ä¸ªè¿‡ç¨‹å®é™…ä¸­éš¾ä»¥workã€‚å› æ­¤ï¼Œå®é™…ä¸­**æ›´æ–°ç”Ÿæˆå™¨çš„å‡†åˆ™æ˜¯æœ€å¤§åŒ–åˆ¤åˆ«å™¨ä½œå‡ºé”™è¯¯åˆ¤æ–­çš„æ¦‚ç‡**ã€‚

è¯¥å°èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†äº¤æ›¿æ‰§è¡Œå¦‚ä¸‹æ›´æ–°ï¼š

1. æœ€å¤§åŒ–åˆ¤åˆ«å™¨ä½œå‡ºé”™è¯¯åˆ¤æ–­çš„æ¦‚ç‡æ¥æ›´æ–°ç”Ÿæˆå™¨ $G$:

$$
\max_{G} \mathbb{E}_{z~p(z)} \left[ \log D(G(z)) \right]
$$

2. æœ€å¤§åŒ–åˆ¤åˆ«å™¨åœ¨çœŸå®æ•°æ®å’Œç”Ÿæˆæ•°æ®ä¸Šä½œå‡ºæ­£ç¡®åˆ¤æ–­çš„æ¦‚ç‡æ¥æ›´æ–°åˆ¤åˆ«å™¨ $D$

$$
\max_{D} \mathbb{E}_{x~p_{data}} \left[ \log D(x) \right] + \mathbb{E}_{z~p_{z}} \left[ \log (1-D(G(z))) \right]
$$


å®é™…ä¸Šï¼Œè‡ª2014å¹´GANæå‡ºä»¥æ¥ï¼Œæœ‰å…³GANçš„è®ºæ–‡å±‚å‡ºä¸ç©·ï¼Œç›¸è¾ƒäºå…¶ä»–çš„ç”Ÿæˆæ¨¡å‹ï¼ŒGANèƒ½ç”Ÿæˆè´¨é‡æœ€é«˜å›¾åƒçš„åŒæ—¶ï¼Œ
ä¹Ÿéœ€è¦é«˜è¶…çš„è®­ç»ƒæŠ€å·§ã€‚è¿™ä¸ª[repo](https://github.com/soumith/ganhacks)é‡ŒåŒ…å«äº†è®­ç»ƒGANçš„17ä¸ªtrickã€‚
æå‡GANè®­ç»ƒçš„ç¨³å®šæ€§å’Œé²æ£’æ€§æ˜¯ä¸€ä¸ªå¼€æ”¾çš„ç ”ç©¶é¢†åŸŸï¼Œæ¯å¤©éƒ½ä¼šç”¨å°çš„paperå‡ºæ¥ã€‚æœ€è¿‘çš„GANæ•™ç¨‹ï¼Œå¯ä»¥çœ‹
[è¿™é‡Œ](https://arxiv.org/abs/1701.00160)ã€‚
æœ€è¿‘å°†ç›®æ ‡å‡½æ•°å˜ä¸ºWassersteinè·ç¦»çš„GANæ¨¡å‹ï¼ˆ[WGAN](https://arxiv.org/abs/1701.07875)ï¼Œ[WGAN-GP](https://arxiv.org/abs/1704.00028)ï¼‰è·å¾—äº†æ›´ç¨³å®šçš„ç»“æœã€‚

éœ€è¦æ³¨æ„çš„æ˜¯ï¼ŒGANä¸æ˜¯è®­ç»ƒç”Ÿæˆæ¨¡å‹çš„å”¯ä¸€æ–¹æ³•ï¼å¦ä¸€ä¸ªæµè¡Œçš„æ–¹æ³•æ˜¯å˜åˆ†è‡ªç¼–ç å™¨ï¼ˆVariational Autoencodersï¼‰
ï¼ˆç”±[here](https://arxiv.org/abs/1312.6114) å’Œ [here](https://arxiv.org/abs/1401.4082)å…±åŒå‘ç°ï¼‰ã€‚VAEæ˜“äºè®­ç»ƒï¼Œä½†å…¶ç”Ÿæˆçš„å›¾åƒè´¨é‡è¿œä¸å¦‚GANã€‚


GANçš„æŸå¤±å‡½æ•°æ˜¯ç”¨BCEï¼ˆBinary Cross-Entropyï¼‰å®šä¹‰çš„ï¼Œä¹Ÿå³æ˜¯å¯¹æ•°å›å½’çš„æŸå¤±å‡½æ•°ï¼š

$$
bce(s,y) = -y * \log(s) - (1-y) * \log(1-s)
$$

è¿™é‡Œçš„$s$ä¸ºç»sigmoidå‡½æ•°ä½œç”¨åå„ä¸ªç±»åˆ«çš„åˆ†æ•°ï¼Œå³ $s = \sigma(x)$ï¼Œå…¶å€¼åœ¨0ï½1ä¹‹é—´ã€‚é‚£ä¹ˆç›´æ¥
è®¡ç®—bce loss çš„æ—¶å€™å°±ä¼šæœ‰æ•°å€¼ä¸ç¨³å®šçš„é—®é¢˜ï¼šè‹¥sçš„å€¼å¾ˆå°ï¼Œé‚£ä¹ˆ $\log(s)$ ä¾¿ä¼šæ¥è¿‘ $-\infty$ã€‚
å› æ­¤ï¼Œéœ€åšå¦‚ä¸‹ä¼˜åŒ–ï¼š

$$
\begin{align}
& -y \log(\sigma(x)) - (1-y) \log(1 - \sigma(x)) \\
&= -y \log(\frac{1}{1+e^{-x}}) - (1-y) \log(e^{-x} - \frac{1}{1+e^{-x}}) \\
&= y \log(1 + e^{-x}) + (1 - y) (x + \log(1 + e^{-x})) \\
&= (1 - y) x + \log(1 + e^{-x}) \\
&= x - xy + \log(1 + e^{-x})  % é¿å… x < 0æ—¶ï¼Œ exp(-x) æº¢å‡º \\
&= -xy + \log(1 + e^x)
\end{align}
$$

ä¸ºäº†ç¡®ä¿ç¨³å®šæ€§ï¼Œå®ç°å¦‚ä¸‹ï¼š

```python
def bce_loss(input, target):
    """
    Numerically stable version of the binary cross-entropy loss function.

    As per https://github.com/pytorch/pytorch/issues/751
    See the TensorFlow docs for a derivation of this formula:
    https://www.tensorflow.org/api_docs/python/tf/nn/sigmoid_cross_entropy_with_logits

    Inputs:
    - input: PyTorch Tensor of shape (N, ) giving scores.
    - target: PyTorch Tensor of shape (N,) containing 0 and 1 giving targets.

    Returns:
    - A PyTorch Tensor containing the mean BCE loss over the minibatch of input data.
    """
    neg_abs = - input.abs()
    loss = input.clamp(min=0) - input * target + (1 + neg_abs.exp()).log()
    return loss.mean()
```

åœ¨æ­¤åŸºç¡€ä¸Šï¼Œä¾¿å¯ä»¥åˆ†åˆ«å®ç°åˆ¤åˆ«å™¨å’Œç”Ÿæˆå™¨çš„æŸå¤±å‡½æ•°äº†ã€‚è¿™é‡Œå°±ä¸è´´ä»£ç äº†ã€‚
åé¢çš„éƒ¨åˆ†æ˜¯ä»‹ç»ä¸åŒçš„GANä»¥åŠå®ç°äº†ã€‚ä½œä¸šå¯ä»¥å‚è€ƒæˆ‘çš„repoï¼š[GANs-Pytorch.ipynb](https://github.com/whu-pzhang/cs231n/blob/master/assignment3/GANs-PyTorch.ipynb)



## æ€»ç»“

ä½œä¸š3çš„å†…å®¹æ›´å¤šçš„æ˜¯å°†æ·±åº¦å­¦ä¹ çš„å¤šä¸ªåº”ç”¨å±•ç¤ºä¸€ä¸‹ï¼Œç„¶åé€šè¿‡ä½œä¸šçš„å½¢å¼æ¥ç†Ÿæ‚‰æ·±åº¦å­¦ä¹ æ¡†æ¶ã€‚
è®¾è®¡åˆ°çš„å†…å®¹å¾ˆä¸°å¯Œï¼Œæƒ³è¦æ·±å…¥ç†è§£çš„è¯ï¼Œéœ€è¦è‡ªå·±å»æŸ¥çœ‹ç›¸å…³æ–‡çŒ®æ‰è¡Œã€‚

è‡³æ­¤ï¼Œcs231nçš„ä½œä¸šç¬”è®°å…¨éƒ¨å®Œæˆï¼ğŸ‰

